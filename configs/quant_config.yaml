dataset:
  scale: 4
  search_subsample: 0.7
  batch_size: 32
  crop_size: 45 # small image,  40x4=160, pathces are 200x200
  files_list:  /home/dev/data_main/SR/DIV2K/processed_200_st70/HR
  debug_mode: False # run on a small porion of data
  
arch:
  bits: [8,4]
  channels: 3
  c_fixed: 36
  scale: 4
  arch_pattern: 
      head: 2
      skip: 1
      tail: 2
      body: 2
      upsample: 1
  body_cells: 3

env:
  run_name: 'BEST_28_ADM_init_0.25'
  gpu: 0
  log_dir: /home/dev/data_main/LOGS/QUANT
  im_dir: 'arch_images'  
  workers: 4 
  seed : 777 
  print_freq: 60 # print frequency
 
search:
  warm_up: 0
  load_path: #/home/dev/data_main/LOGS/QUANT/SEARCH_PRETRAIN_V2-2021-12-10-17/best.pth.tar
  
  penalty: 0.0
  alpha_selector: softmax #softmax #gumbel
  sparse_type: entropy # l1_softmax # l1 # entropy # none
  sparse_coef: 1e-4 # 0.01 for entropy, 0.0001 for l1
  optimizer: adam

  lr_scheduler: cosine
  w_lr: 1e-3 # lr for weights
  w_lr_min: 0.0001 # minimum lr for weights
  w_momentum: 0.9 # momentum for weights
  w_weight_decay: 3e-8 # weight decay for weights
  w_grad_clip: 5 # gradient clipping for weights
  epochs: 15 # n of training epochs
  temperature_start: 1e1
  temp_red: 0.6
  alpha_lr:  3e-4 # lr for alpha
  alpha_weight_decay: 0 #1e-3 #weight decay for alpha
  
train:
  warm_up: 0
  lr_scheduler: cosine
  lr : 1e-4 # lr for weights
  weight_decay : 0 # weight decay
  print_freq : 200 # print frequency
  epochs : 30 # # of training epochs
  genotype_path:  /home/dev/data_main/LOGS/QUANT/adam_entropy_s_two/trail_1/SEARCH_batch experiment_penalty_0_trail_1-2021-12-10-13/best_arch.gen


